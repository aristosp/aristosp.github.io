---
title: "What does an Audio-Visual Speech Recognition Model know about Visemes?"
collection: publications
category: conferences
permalink: /publication/ukis_2025
excerpt: 'Phonemes are the basic speech unit with numerous studies exploring the inner workings of end-to-end transformer-based speech models, but they have mainly focused on Audio Speech Recognition (ASR). These studies have shown that there is significant phoneme capturing and encoding within the encoderlayers. The methodologies found in the literature include probing and the use of similarity measures, among others. Considerably less investigation into the interpretability of Audio-Visual Speech Recognition (AVSR) models has been done. In particular, no work has explored what AVSR models learn about visemes, the visual equivalent of phonemes. Our work therefore utilizes the concepts developed for ASR and applies them to AV-HuBERT, where a thorough analysis is performed to establish what the model learns about visemes.'
date: 2025-06-17
venue: 'GitHub Journal of Bugs'
paperurl: 'http://aristosp.github.io/files/UKIS_2025_Aristeidis_Papadopoulos_v2.pdf'
citation: 'Papadopoulos, Aristeidis. (2024). &quot;What does an Audio-Visual Speech Recognition Model know about Visemes?&quot;'
---

The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.
